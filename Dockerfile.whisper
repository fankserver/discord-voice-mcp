# Build stage for Go binary
FROM golang:1.24-alpine3.21 AS go-builder

# Install build dependencies
# hadolint ignore=DL3018
RUN apk add --no-cache git gcc musl-dev pkgconfig opus-dev

WORKDIR /app

# Copy go mod files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build binary with CGO
# Using dynamic linking as static opus lib not available for all architectures
RUN CGO_ENABLED=1 go build -ldflags '-w -s' \
    -o discord-voice-mcp ./cmd/discord-voice-mcp

# Build whisper.cpp from source for both architectures
# This ensures compatibility with both AMD64 and ARM64
FROM ubuntu:22.04 AS whisper-builder

ARG TARGETARCH

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    cmake \
    git \
    ca-certificates \
    libopenblas-dev \
    && rm -rf /var/lib/apt/lists/*

# Clone and build whisper.cpp
WORKDIR /build
RUN git clone --depth 1 https://github.com/ggml-org/whisper.cpp.git && \
    cd whisper.cpp && \
    if [ "${TARGETARCH}" = "amd64" ]; then \
        # For AMD64: Enable AVX optimizations
        cmake -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DGGML_BLAS=ON \
            -DGGML_BLAS_VENDOR=OpenBLAS \
            -DGGML_AVX=ON \
            -DGGML_AVX2=ON \
            -DBUILD_SHARED_LIBS=ON; \
    else \
        # For ARM64: Enable NEON optimizations
        cmake -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DGGML_BLAS=ON \
            -DGGML_BLAS_VENDOR=OpenBLAS \
            -DGGML_ARM_NEON=ON \
            -DBUILD_SHARED_LIBS=ON; \
    fi && \
    cmake --build build --config Release -j$(nproc)

# Architecture-specific base image selection
# AMD64: Use minimal CUDA base for GPU support (Windows/Linux with NVIDIA GPUs)
# ARM64: Use standard Ubuntu for Apple Silicon Macs and ARM servers
ARG TARGETARCH

# Final stage with architecture-specific base
# Using cuda-base instead of cuda-runtime saves ~1.5GB
FROM nvidia/cuda:12.2.0-base-ubuntu22.04 AS base-amd64
FROM ubuntu:22.04 AS base-arm64

# Select the appropriate base image based on architecture
FROM base-${TARGETARCH} AS final

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Install runtime dependencies
# Only runtime libraries needed, not build tools
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libopus0 \
    libgomp1 \
    libopenblas0 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy Go binary from builder
COPY --from=go-builder /app/discord-voice-mcp .

# Copy whisper binaries from builder
COPY --from=whisper-builder /build/whisper.cpp/build/bin/whisper-cli /usr/local/bin/whisper
COPY --from=whisper-builder /build/whisper.cpp/build/bin/whisper-server /usr/local/bin/whisper-server

# Copy whisper shared libraries
COPY --from=whisper-builder /build/whisper.cpp/build/src/libwhisper.so* /usr/local/lib/
COPY --from=whisper-builder /build/whisper.cpp/build/ggml/src/libggml*.so* /usr/local/lib/

# Update library cache
RUN ldconfig

# Create directories and add user
RUN mkdir -p /models && \
    useradd -m -u 1000 -s /bin/bash mcp

USER mcp

# Set default transcriber type for whisper image
ENV TRANSCRIBER_TYPE=whisper

# Architecture-specific notes:
# AMD64: Can use NVIDIA GPU acceleration if available (Windows/Linux)
# ARM64: Optimized for CPU with ARM NEON instructions (Apple Silicon, ARM servers)
# GPU acceleration in Docker on macOS is not effective due to virtualization limitations

# Run the binary
CMD ["./discord-voice-mcp"]

# Usage Examples:
# 
# Windows/Linux with NVIDIA GPU (amd64):
#   docker run --gpus all -i --rm \
#     -e DISCORD_TOKEN="your-bot-token" \
#     -e DISCORD_USER_ID="your-discord-user-id" \
#     -e TRANSCRIBER_TYPE="whisper" \
#     -e WHISPER_MODEL_PATH="/models/ggml-base.bin" \
#     -v $(pwd)/models:/models:ro \
#     ghcr.io/fankserver/discord-voice-mcp:whisper
#
# macOS with Apple Silicon (arm64):
#   docker run -i --rm \
#     -e DISCORD_TOKEN="your-bot-token" \
#     -e DISCORD_USER_ID="your-discord-user-id" \
#     -e TRANSCRIBER_TYPE="whisper" \
#     -e WHISPER_MODEL_PATH="/models/ggml-base.bin" \
#     -v $(pwd)/models:/models:ro \
#     ghcr.io/fankserver/discord-voice-mcp:whisper
#
# Note: For best performance on Apple Silicon Macs, consider running natively
# instead of in Docker, as Metal GPU acceleration is not available in containers.