# Build stage for Go binary
FROM golang:1.24-alpine3.21 AS go-builder

# Install build dependencies
# hadolint ignore=DL3018
RUN apk add --no-cache git gcc musl-dev pkgconfig opus-dev

WORKDIR /app

# Copy go mod files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build binary with CGO
# Using dynamic linking as static opus lib not available for all architectures
RUN CGO_ENABLED=1 go build -ldflags '-w -s' \
    -o discord-voice-mcp ./cmd/discord-voice-mcp

# Build stage for whisper.cpp with multiple acceleration backends
# Using NVIDIA CUDA base image to support CUDA compilation
FROM nvidia/cuda:12.2.0-devel-ubuntu22.04 AS whisper-builder

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Pin to a specific version for reproducible builds
ARG WHISPER_CPP_VERSION=v1.7.3

# Build args for GPU support (can be overridden at build time)
# Default: Build with CUDA, ROCm, Vulkan, and OpenBLAS for maximum compatibility
ARG GGML_CUDA=ON
ARG GGML_ROCM=ON
ARG GGML_SYCL=OFF
ARG GGML_VULKAN=ON
ARG GGML_OPENBLAS=ON

# Install build dependencies (combined for efficiency)
# Includes base tools, OpenBLAS for CPU acceleration, and Vulkan SDK
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    git cmake make g++ pkg-config \
    libopenblas-dev \
    libvulkan-dev vulkan-tools \
    && rm -rf /var/lib/apt/lists/*

# Install ROCm headers for AMD GPU support (minimal, for compilation only)
# Full ROCm is huge, so we just get what's needed for building
# Note: ROCm is only available on x86_64 architecture
# hadolint ignore=DL3008,SC2086
RUN ARCH=$(dpkg --print-architecture) && \
    if [ "$ARCH" = "amd64" ]; then \
        apt-get update && apt-get install -y --no-install-recommends wget gnupg ca-certificates && \
        mkdir -p /etc/apt/keyrings && \
        wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | gpg --dearmor -o /etc/apt/keyrings/rocm.gpg && \
        echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/debian/ ubuntu main" \
            > /etc/apt/sources.list.d/rocm.list && \
        apt-get update && \
        (apt-get install -y --no-install-recommends rocm-dev || \
            echo "Warning: ROCm dev packages not available, AMD GPU support disabled") && \
        rm -rf /var/lib/apt/lists/*; \
    else \
        echo "Info: Skipping ROCm installation on $ARCH architecture"; \
    fi

# Clone whisper.cpp (separate layer for better caching)
WORKDIR /build
RUN git clone --depth 1 --branch ${WHISPER_CPP_VERSION} https://github.com/ggerganov/whisper.cpp.git

# Build whisper.cpp with multiple acceleration backends
# Will use first available at runtime: CUDA -> ROCm -> Vulkan -> OpenBLAS
WORKDIR /build/whisper.cpp
# hadolint ignore=SC2086
RUN ARCH=$(dpkg --print-architecture) && \
    if [ "$ARCH" = "amd64" ]; then \
        ROCM_FLAG="${GGML_ROCM}"; \
        CUDA_ARCHS="60;61;70;75;80;86;89;90"; \
    elif [ "$ARCH" = "arm64" ]; then \
        ROCM_FLAG="OFF"; \
        CUDA_ARCHS="53;62;72;87"; \
        echo "Info: Disabling ROCm on $ARCH architecture, using ARM CUDA architectures"; \
    else \
        ROCM_FLAG="OFF"; \
        CUDA_ARCHS="60;70;75;80"; \
        echo "Info: Disabling ROCm on $ARCH architecture"; \
    fi && \
    cmake -B build \
        -DCMAKE_BUILD_TYPE=Release \
        -DGGML_CCACHE=OFF \
        -DGGML_OPENBLAS="${GGML_OPENBLAS}" \
        -DGGML_CUDA="${GGML_CUDA}" \
        -DCMAKE_CUDA_ARCHITECTURES="${CUDA_ARCHS}" \
        -DGGML_ROCM="${ROCM_FLAG}" \
        -DGGML_SYCL="${GGML_SYCL}" \
        -DGGML_VULKAN="${GGML_VULKAN}" \
        . && \
    cmake --build build --config Release -- -j"$(nproc)" && \
    chmod +x build/bin/* && \
    # Show which acceleration backends were built
    echo "Built with acceleration support:" && \
    ldd build/bin/main | grep -E "cuda|hip|vulkan|blas" || echo "Checking acceleration..."

# Final stage - using NVIDIA runtime as base for GPU support
# This image will work with CPU-only as well (graceful fallback)
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Install runtime dependencies for all acceleration backends
# Includes ffmpeg, audio libs, OpenBLAS, Vulkan, and optionally ROCm runtime
# hadolint ignore=DL3008,SC2086
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libopus0 \
    libgomp1 \
    libopenblas0 \
    libvulkan1 \
    mesa-vulkan-drivers \
    && rm -rf /var/lib/apt/lists/* && \
    ARCH=$(dpkg --print-architecture) && \
    if [ "$ARCH" = "amd64" ]; then \
        apt-get update && \
        (apt-get install -y --no-install-recommends rocm-libs || \
            echo "Info: ROCm runtime not available, AMD GPU support will be disabled") && \
        rm -rf /var/lib/apt/lists/*; \
    else \
        echo "Info: Skipping ROCm runtime on $ARCH architecture"; \
    fi

WORKDIR /app

# Copy Go binary from builder
COPY --from=go-builder /app/discord-voice-mcp .

# Copy whisper binaries from builder  
COPY --from=whisper-builder /build/whisper.cpp/build/bin/main /usr/local/bin/whisper
COPY --from=whisper-builder /build/whisper.cpp/build/bin/server /usr/local/bin/whisper-server
# Copy whisper shared libraries from correct directories
COPY --from=whisper-builder /build/whisper.cpp/build/src/libwhisper.so* /usr/local/lib/
COPY --from=whisper-builder /build/whisper.cpp/build/ggml/src/libggml*.so* /usr/local/lib/
# Update library cache, create directories, and add user
RUN ldconfig && \
    mkdir -p /models && \
    useradd -m -u 1000 -s /bin/bash mcp
USER mcp

# Set default transcriber type for whisper image
ENV TRANSCRIBER_TYPE=whisper

# GPU acceleration is automatically detected at runtime
# Priority order: CUDA (NVIDIA) -> ROCm (AMD) -> Vulkan (Any GPU) -> OpenBLAS (CPU)
# To force CPU-only: set WHISPER_USE_GPU=false

# Run the binary
CMD ["./discord-voice-mcp"]

# Usage:
# - NVIDIA GPU: docker run --gpus all ...
# - AMD GPU: docker run --device=/dev/kfd --device=/dev/dri --group-add video ...
# - Intel/Other GPU (Vulkan): docker run --device=/dev/dri ...
# - CPU only: docker run ... (no special flags needed)