# Build stage for Go binary
FROM golang:1.24-alpine3.21 AS go-builder

# Install build dependencies
# hadolint ignore=DL3018
RUN apk add --no-cache git gcc musl-dev pkgconfig opus-dev

WORKDIR /app

# Copy go mod files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build binary with CGO
# Using dynamic linking as static opus lib not available for all architectures
RUN CGO_ENABLED=1 go build -ldflags '-w -s' \
    -o discord-voice-mcp ./cmd/discord-voice-mcp

# Use prebuilt whisper.cpp CUDA image to extract binaries
# This dramatically reduces build time from 2+ hours to minutes
# The ghcr.io/ggml-org/whisper.cpp:main-cuda image includes:
# - whisper-cli with CUDA, ROCm, Vulkan, and OpenBLAS support
# - ffmpeg and other required tools
FROM ghcr.io/ggml-org/whisper.cpp:main-cuda AS whisper-source

# Final stage - using NVIDIA runtime as base for GPU support
# This image will work with CPU-only as well (graceful fallback)
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Install runtime dependencies
# Only runtime libraries needed, not build tools
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libopus0 \
    libgomp1 \
    libopenblas0 \
    libvulkan1 \
    mesa-vulkan-drivers \
    && rm -rf /var/lib/apt/lists/*

# Install ROCm runtime for AMD GPU support (optional, only on amd64)
# hadolint ignore=DL3008,SC2086
RUN ARCH=$(dpkg --print-architecture) && \
    if [ "$ARCH" = "amd64" ]; then \
        apt-get update && \
        (apt-get install -y --no-install-recommends rocm-libs 2>/dev/null || \
            echo "Info: ROCm runtime not available, AMD GPU support will be disabled") && \
        rm -rf /var/lib/apt/lists/*; \
    else \
        echo "Info: Skipping ROCm runtime on $ARCH architecture"; \
    fi

WORKDIR /app

# Copy Go binary from builder
COPY --from=go-builder /app/discord-voice-mcp .

# Copy whisper binaries from prebuilt image
# The prebuilt image has whisper-cli in /app
COPY --from=whisper-source /app/whisper-cli /usr/local/bin/whisper
# Some versions might have whisper-server, copy if exists
COPY --from=whisper-source /app/whisper-server /usr/local/bin/whisper-server 2>/dev/null || true

# Create directories and add user
RUN mkdir -p /models && \
    useradd -m -u 1000 -s /bin/bash mcp

USER mcp

# Set default transcriber type for whisper image
ENV TRANSCRIBER_TYPE=whisper

# GPU acceleration is automatically detected at runtime
# Priority order: CUDA (NVIDIA) -> ROCm (AMD) -> Vulkan (Any GPU) -> OpenBLAS (CPU)
# To force CPU-only: set WHISPER_USE_GPU=false

# Run the binary
CMD ["./discord-voice-mcp"]

# Usage:
# - NVIDIA GPU: docker run --gpus all ...
# - AMD GPU: docker run --device=/dev/kfd --device=/dev/dri --group-add video ...
# - Intel/Other GPU (Vulkan): docker run --device=/dev/dri ...
# - CPU only: docker run ... (no special flags needed)