# Build stage for Go binary
FROM golang:1.24-alpine3.21 AS go-builder

# Install build dependencies
# hadolint ignore=DL3018
RUN apk add --no-cache git gcc musl-dev pkgconfig opus-dev

WORKDIR /app

# Copy go mod files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build binary with CGO
# Using dynamic linking as static opus lib not available for all architectures
RUN CGO_ENABLED=1 go build -ldflags '-w -s' \
    -o discord-voice-mcp ./cmd/discord-voice-mcp

# Use prebuilt whisper.cpp image to extract binaries
# This dramatically reduces build time from 2+ hours to minutes
# Using 'main' tag which supports both linux/amd64 and linux/arm64
FROM ghcr.io/ggml-org/whisper.cpp:main AS whisper-source

# Architecture-specific base image selection
# AMD64: Use minimal CUDA base for GPU support (Windows/Linux with NVIDIA GPUs)
# ARM64: Use standard Ubuntu for Apple Silicon Macs and ARM servers
ARG TARGETARCH

# Final stage with architecture-specific base
# Using cuda-base instead of cuda-runtime saves ~1.5GB
FROM nvidia/cuda:12.2.0-base-ubuntu22.04 AS base-amd64
FROM ubuntu:22.04 AS base-arm64

# Select the appropriate base image based on architecture
FROM base-${TARGETARCH} AS final

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Install runtime dependencies
# Only runtime libraries needed, not build tools
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libopus0 \
    libgomp1 \
    libopenblas0 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy Go binary from builder
COPY --from=go-builder /app/discord-voice-mcp .

# Copy whisper binaries from prebuilt image
# The prebuilt image has binaries in /app/build/bin/
COPY --from=whisper-source /app/build/bin/whisper-cli /usr/local/bin/whisper
COPY --from=whisper-source /app/build/bin/whisper-server /usr/local/bin/whisper-server

# Copy whisper shared libraries
COPY --from=whisper-source /app/build/src/libwhisper.so* /usr/local/lib/
COPY --from=whisper-source /app/build/ggml/src/libggml*.so* /usr/local/lib/

# Update library cache
RUN ldconfig

# Create directories and add user
RUN mkdir -p /models && \
    useradd -m -u 1000 -s /bin/bash mcp

USER mcp

# Set default transcriber type for whisper image
ENV TRANSCRIBER_TYPE=whisper

# Architecture-specific notes:
# AMD64: Can use NVIDIA GPU acceleration if available (Windows/Linux)
# ARM64: Optimized for CPU with ARM NEON instructions (Apple Silicon, ARM servers)
# GPU acceleration in Docker on macOS is not effective due to virtualization limitations

# Run the binary
CMD ["./discord-voice-mcp"]

# Usage Examples:
# 
# Windows/Linux with NVIDIA GPU (amd64):
#   docker run --gpus all -i --rm \
#     -e DISCORD_TOKEN="your-bot-token" \
#     -e DISCORD_USER_ID="your-discord-user-id" \
#     -e TRANSCRIBER_TYPE="whisper" \
#     -e WHISPER_MODEL_PATH="/models/ggml-base.bin" \
#     -v $(pwd)/models:/models:ro \
#     ghcr.io/fankserver/discord-voice-mcp:whisper
#
# macOS with Apple Silicon (arm64):
#   docker run -i --rm \
#     -e DISCORD_TOKEN="your-bot-token" \
#     -e DISCORD_USER_ID="your-discord-user-id" \
#     -e TRANSCRIBER_TYPE="whisper" \
#     -e WHISPER_MODEL_PATH="/models/ggml-base.bin" \
#     -v $(pwd)/models:/models:ro \
#     ghcr.io/fankserver/discord-voice-mcp:whisper
#
# Note: For best performance on Apple Silicon Macs, consider running natively
# instead of in Docker, as Metal GPU acceleration is not available in containers.