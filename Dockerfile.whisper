# Build stage for Go binary
FROM golang:1.24-alpine3.21 AS go-builder

# Install build dependencies
# hadolint ignore=DL3018
RUN apk add --no-cache git gcc musl-dev pkgconfig opus-dev

WORKDIR /app

# Copy go mod files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build binary with CGO
# Using dynamic linking as static opus lib not available for all architectures
RUN CGO_ENABLED=1 go build -ldflags '-w -s' \
    -o discord-voice-mcp ./cmd/discord-voice-mcp

# Use prebuilt whisper.cpp image to extract binaries
# This dramatically reduces build time from 2+ hours to minutes
# Using 'main' tag which supports both linux/amd64 and linux/arm64
# Note: CUDA support is not precompiled in the main image, but it includes
# CPU optimizations (OpenBLAS) which still provide good performance
FROM ghcr.io/ggml-org/whisper.cpp:main AS whisper-source

# Final stage - using NVIDIA runtime as base for GPU support (if available)
# This image will work with CPU-only as well (graceful fallback)
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Set shell with pipefail for better error handling
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Install runtime dependencies
# Only runtime libraries needed, not build tools
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libopus0 \
    libgomp1 \
    libopenblas0 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy Go binary from builder
COPY --from=go-builder /app/discord-voice-mcp .

# Copy whisper binaries from prebuilt image
# The prebuilt image has binaries in /app/build/bin/
COPY --from=whisper-source /app/build/bin/whisper-cli /usr/local/bin/whisper
COPY --from=whisper-source /app/build/bin/whisper-server /usr/local/bin/whisper-server

# Copy whisper shared libraries
COPY --from=whisper-source /app/build/src/libwhisper.so* /usr/local/lib/
COPY --from=whisper-source /app/build/ggml/src/libggml*.so* /usr/local/lib/

# Update library cache
RUN ldconfig

# Create directories and add user
RUN mkdir -p /models && \
    useradd -m -u 1000 -s /bin/bash mcp

USER mcp

# Set default transcriber type for whisper image
ENV TRANSCRIBER_TYPE=whisper

# Note: This image uses CPU-optimized whisper.cpp (OpenBLAS)
# For GPU acceleration, consider building from source with CUDA/ROCm support

# Run the binary
CMD ["./discord-voice-mcp"]

# Usage:
# docker run -i --rm \
#   -e DISCORD_TOKEN="your-bot-token" \
#   -e DISCORD_USER_ID="your-discord-user-id" \
#   -e TRANSCRIBER_TYPE="whisper" \
#   -e WHISPER_MODEL_PATH="/models/ggml-base.bin" \
#   -v $(pwd)/models:/models:ro \
#   ghcr.io/fankserver/discord-voice-mcp:whisper